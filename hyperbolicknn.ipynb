{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":29446,"sourceType":"datasetVersion","datasetId":22987}],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nimport scipy.sparse as sp\nfrom tqdm import tqdm\n\nEPS = 1e-5","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-20T11:30:52.594635Z","iopub.execute_input":"2025-12-20T11:30:52.595125Z","iopub.status.idle":"2025-12-20T11:30:57.094592Z","shell.execute_reply.started":"2025-12-20T11:30:52.595100Z","shell.execute_reply":"2025-12-20T11:30:57.093958Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Импорты и глобальная конфигурация\nimport os, glob, math, pickle, time\nfrom collections import defaultdict, Counter\n\nimport numpy as np\nimport pandas as pd\n\nfrom scipy import sparse\nfrom sklearn.preprocessing import normalize\nfrom sklearn.decomposition import TruncatedSVD\n\nimport matplotlib.pyplot as plt\n\nRANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)\n\n# --- Fast dev mode ---\nDEV_MODE = True\nMAX_USERS = 8000 if DEV_MODE else None  # None для полного прогона\n\nMIN_BASKETS_PER_USER = 3  # должно быть >= 3, чтобы можно было сделать train/val/test\n\n# ---Метрики и размер списка рекомендаций---\nTOPK_LIST = [5, 10, 20]\nTOPN_RECOMMEND = 200  # внутренняя длина списка кандидатов (сколько объектов ранжируем)\n\n\n# --- UserKNN ---\nUSERKNN_TUNE_GRID = [50, 100, 200, 500]  # значения числа соседей для подбора\nUSERKNN_DEFAULT_K = 200\n\n# --- TIFU-KNN(simple) ---\nTIFU_GROUPS_GRID = [5, 7]              # варианты числа групп истории\nTIFU_ALPHA_GRID = [0.5, 0.7, 0.9]      # варианты смешивания PIF/IU\nTIFU_NEIGHBORS_GRID = [100, 300]       # варианты числа соседей\n\n# --- ItemKNN (добавляем, чтобы \"KNN baseline\" был однозначно покрыт) ---\nITEMKNN_TUNE_GRID = [50, 100, 200]   # сколько похожих items хранить на item (topK)\nITEMKNN_DEFAULT_K = 100\n\n\nTIFU_WITHIN_DECAY = 0.9  # затухание внутри группы\nTIFU_GROUP_DECAY = 0.7   # затухание между группами\nTIFU_DEFAULT_GROUPS = 7\nTIFU_DEFAULT_ALPHA = 0.7\nTIFU_DEFAULT_K = 300\n\nprint(\"DEV_MODE:\", DEV_MODE, \"MAX_USERS:\", MAX_USERS)\n\ndef find_csv_candidate():\n    # Ищем CSV-файлы в папке Kaggle input\n    cands = glob.glob('/kaggle/input/*/*.csv') + glob.glob('/kaggle/input/*/*.CSV')\n    if not cands:\n        raise FileNotFoundError('В /kaggle/input не найдены CSV. Проверьте, что датасет добавлен в ноутбук.')\n\n    # Предпочитаем файл, который похож на Ta-Feng по названию\n    for p in cands:\n        low = p.lower()\n        if ('ta' in low and 'feng' in low) or ('tafeng' in low):\n            return p\n\n    # Если не нашли — берём самый большой CSV (как запасной вариант)\n    cands = sorted(cands, key=lambda p: os.path.getsize(p), reverse=True)\n    return cands[0]\n\ndef detect_columns(df: pd.DataFrame):\n    cols = {c.lower(): c for c in df.columns}\n\n    def pick(candidates):\n        for c in candidates:\n            if c in cols:\n                return cols[c]\n        return None\n\n    user_col = pick(['customer_id', 'cust_id', 'user_id', 'userid', 'member_id', 'client_id'])\n    item_col = pick(['product_id', 'item_id', 'prod_id', 'sku_id', 'article_id'])\n    date_col = pick(['transaction_dt', 'trans_date', 'date', 't_dat', 'datetime', 'transaction_date'])\n\n    # В Ta-Feng часто встречаются имена в верхнем регистре: CUSTOMER_ID, PRODUCT_ID, TRANSACTION_DT\n    if user_col is None:\n        for c in df.columns:\n            if c.upper() == 'CUSTOMER_ID':\n                user_col = c\n                break\n    if item_col is None:\n        for c in df.columns:\n            if c.upper() == 'PRODUCT_ID':\n                item_col = c\n                break\n    if date_col is None:\n        for c in df.columns:\n            if c.upper() == 'TRANSACTION_DT':\n                date_col = c\n                break\n\n    return user_col, item_col, date_col\n\npath = find_csv_candidate()\nprint(\"Using CSV:\", path)\n\ndf = pd.read_csv(path)\nprint(\"Shape:\", df.shape)\nprint(\"Columns:\", list(df.columns)[:30])\n\nuser_col, item_col, date_col = detect_columns(df)\nprint(\"Detected columns:\", {\"user_col\": user_col, \"item_col\": item_col, \"date_col\": date_col})\n\nif user_col is None or item_col is None or date_col is None:\n    raise ValueError(\n        \"Не удалось автоматически определить необходимые колонки. \"\n        \"Пожалуйста, задайте user_col/item_col/date_col вручную после просмотра df.columns.\"\n    )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-20T11:30:57.095650Z","iopub.execute_input":"2025-12-20T11:30:57.096020Z","iopub.status.idle":"2025-12-20T11:30:59.073178Z","shell.execute_reply.started":"2025-12-20T11:30:57.095993Z","shell.execute_reply":"2025-12-20T11:30:59.072558Z"}},"outputs":[{"name":"stdout","text":"DEV_MODE: True MAX_USERS: 8000\nUsing CSV: /kaggle/input/ta-feng-grocery-dataset/ta_feng_all_months_merged.csv\nShape: (817741, 9)\nColumns: ['TRANSACTION_DT', 'CUSTOMER_ID', 'AGE_GROUP', 'PIN_CODE', 'PRODUCT_SUBCLASS', 'PRODUCT_ID', 'AMOUNT', 'ASSET', 'SALES_PRICE']\nDetected columns: {'user_col': 'CUSTOMER_ID', 'item_col': 'PRODUCT_ID', 'date_col': 'TRANSACTION_DT'}\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Приводим типы к строкам (важно, чтобы не потерять ведущие нули в идентификаторах)\ndf[user_col] = df[user_col].astype(str)\ndf[item_col] = df[item_col].astype(str)\n\n# Парсим дату, некорректные строки превращаются в NaT\ndf[date_col] = pd.to_datetime(df[date_col], errors='coerce')\n\n# Удаляем строки без даты/пользователя/товара\ndf = df.dropna(subset=[date_col, user_col, item_col]).copy()\n\n# Округляем datetime вниз до даты (без времени)\ndf['__date'] = df[date_col].dt.floor('D')\n\n# Группировка в корзины\nbasket_df = (\n    df.groupby([user_col, '__date'])[item_col]\n      .apply(lambda s: list(pd.unique(s)))   # уникальные товары в корзине\n      .reset_index()\n      .rename(columns={user_col: 'user_raw', '__date': 'date', item_col: 'items_raw'})\n)\n\nbasket_df = basket_df.sort_values(['user_raw', 'date']).reset_index(drop=True)\nprint(\"Baskets:\", basket_df.shape, \"Unique users:\", basket_df['user_raw'].nunique())\nbasket_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-20T11:30:59.074045Z","iopub.execute_input":"2025-12-20T11:30:59.074314Z","iopub.status.idle":"2025-12-20T11:31:05.884409Z","shell.execute_reply.started":"2025-12-20T11:30:59.074292Z","shell.execute_reply":"2025-12-20T11:31:05.883796Z"}},"outputs":[{"name":"stdout","text":"Baskets: (119578, 3) Unique users: 32266\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"  user_raw       date                                          items_raw\n0   100021 2000-11-03  [9310042571491, 4719783004070, 4711049230223, ...\n1   100021 2000-11-05  [4710018004605, 4719111020109, 4710247005299, ...\n2   100021 2000-11-19  [4711686002016, 47106710, 4711686002528, 47102...\n3   100021 2000-11-28  [4711800531385, 4714981010038, 4710339772139, ...\n4   100021 2000-12-02  [4710088436511, 4710094014741, 4710105045443, ...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_raw</th>\n      <th>date</th>\n      <th>items_raw</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>100021</td>\n      <td>2000-11-03</td>\n      <td>[9310042571491, 4719783004070, 4711049230223, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>100021</td>\n      <td>2000-11-05</td>\n      <td>[4710018004605, 4719111020109, 4710247005299, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>100021</td>\n      <td>2000-11-19</td>\n      <td>[4711686002016, 47106710, 4711686002528, 47102...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>100021</td>\n      <td>2000-11-28</td>\n      <td>[4711800531385, 4714981010038, 4710339772139, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>100021</td>\n      <td>2000-12-02</td>\n      <td>[4710088436511, 4710094014741, 4710105045443, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"from collections import defaultdict\nimport numpy as np\nimport pandas as pd\n\n# Фильтруем пользователей с достаточным числом корзин:\n#    нам нужно минимум 3 корзины на пользователя, чтобы сформировать train/val/test\ncounts = basket_df.groupby('user_raw').size()\nkeep_users = counts[counts >= MIN_BASKETS_PER_USER].index\nbasket_df = basket_df[basket_df['user_raw'].isin(keep_users)].copy()\n\n# Опционально: режим разработки (dev).\n#    Если задан MAX_USERS, берём только первых N пользователей (после сортировки/порядка появления).\n#    Это ускоряет эксперименты и отладку в Kaggle.\nif MAX_USERS is not None:\n    users = basket_df['user_raw'].unique()[:MAX_USERS]\n    basket_df = basket_df[basket_df['user_raw'].isin(users)].copy()\n\n# На всякий случай пересортируем по пользователю и времени,\n#    чтобы дальнейший split по времени был корректным\nbasket_df = basket_df.sort_values(['user_raw', 'date']).reset_index(drop=True)\nprint(\"After filter/dev: baskets\", basket_df.shape, \"users\", basket_df['user_raw'].nunique())\n\n# Маппинг сырого user/item ID в индексы 0..n-1\n#    Это нужно для эффективной работы с матрицами (scipy.sparse) и моделями.\nuser_ids = basket_df['user_raw'].unique()\nitem_ids = pd.unique(np.concatenate(basket_df['items_raw'].values))\n\nuser2idx = {u: i for i, u in enumerate(user_ids)}\nitem2idx = {it: i for i, it in enumerate(item_ids)}\n\n# обратные отображения (удобно для дебага/вывода рекомендаций)\nidx2user = {i: u for u, i in user2idx.items()}\nidx2item = {i: it for it, i in item2idx.items()}\n\n# 5) Добавляем индекс пользователя и переводим списки товаров в список индексов\nbasket_df['u'] = basket_df['user_raw'].map(user2idx)\nbasket_df['item_idx_list'] = basket_df['items_raw'].apply(lambda xs: [item2idx[x] for x in xs])\n\nn_users = len(user2idx)\nn_items = len(item2idx)\nprint(\"n_users:\", n_users, \"n_items:\", n_items)\n\ndisplay(basket_df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-20T11:31:05.885939Z","iopub.execute_input":"2025-12-20T11:31:05.886174Z","iopub.status.idle":"2025-12-20T11:31:06.319613Z","shell.execute_reply.started":"2025-12-20T11:31:05.886152Z","shell.execute_reply":"2025-12-20T11:31:06.318858Z"}},"outputs":[{"name":"stdout","text":"After filter/dev: baskets (53734, 3) users 8000\nn_users: 8000 n_items: 21149\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  user_raw       date                                          items_raw  u  \\\n0   100021 2000-11-03  [9310042571491, 4719783004070, 4711049230223, ...  0   \n1   100021 2000-11-05  [4710018004605, 4719111020109, 4710247005299, ...  0   \n2   100021 2000-11-19  [4711686002016, 47106710, 4711686002528, 47102...  0   \n3   100021 2000-11-28  [4711800531385, 4714981010038, 4710339772139, ...  0   \n4   100021 2000-12-02  [4710088436511, 4710094014741, 4710105045443, ...  0   \n\n                                      item_idx_list  \n0                                [0, 1, 2, 3, 4, 5]  \n1              [6, 7, 8, 9, 10, 11, 12, 13, 14, 15]  \n2  [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27]  \n3      [28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]  \n4                              [32, 39, 20, 40, 41]  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_raw</th>\n      <th>date</th>\n      <th>items_raw</th>\n      <th>u</th>\n      <th>item_idx_list</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>100021</td>\n      <td>2000-11-03</td>\n      <td>[9310042571491, 4719783004070, 4711049230223, ...</td>\n      <td>0</td>\n      <td>[0, 1, 2, 3, 4, 5]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>100021</td>\n      <td>2000-11-05</td>\n      <td>[4710018004605, 4719111020109, 4710247005299, ...</td>\n      <td>0</td>\n      <td>[6, 7, 8, 9, 10, 11, 12, 13, 14, 15]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>100021</td>\n      <td>2000-11-19</td>\n      <td>[4711686002016, 47106710, 4711686002528, 47102...</td>\n      <td>0</td>\n      <td>[16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>100021</td>\n      <td>2000-11-28</td>\n      <td>[4711800531385, 4714981010038, 4710339772139, ...</td>\n      <td>0</td>\n      <td>[28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>100021</td>\n      <td>2000-12-02</td>\n      <td>[4710088436511, 4710094014741, 4710105045443, ...</td>\n      <td>0</td>\n      <td>[32, 39, 20, 40, 41]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"user_baskets = defaultdict(list)  # u -> list of (date, [items])\nfor row in basket_df.itertuples(index=False):\n    user_baskets[row.u].append((row.date, row.item_idx_list))\n\n# Гарантируем сортировку по времени (вдруг где-то нарушилась)\nfor u in user_baskets:\n    user_baskets[u] = sorted(user_baskets[u], key=lambda x: x[0])\n\ntrain_hist = {}\nval_basket = {}\ntest_basket = {}\n\nfor u, seq in user_baskets.items():\n    baskets = [b for _, b in seq]\n    # На всякий случай проверяем минимальную длину\n    if len(baskets) < 3:\n        continue\n    train_hist[u] = baskets[:-2]   # все корзины, кроме двух последних\n    val_basket[u]  = baskets[-2]   # предпоследняя корзина\n    test_basket[u] = baskets[-1]   # последняя корзина\n\nprint(\"Users with train/val/test:\", len(train_hist))\nassert len(train_hist) > 0, \"No users available after filtering/splitting.\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-20T11:31:06.320598Z","iopub.execute_input":"2025-12-20T11:31:06.320903Z","iopub.status.idle":"2025-12-20T11:31:06.612371Z","shell.execute_reply.started":"2025-12-20T11:31:06.320874Z","shell.execute_reply":"2025-12-20T11:31:06.611548Z"}},"outputs":[{"name":"stdout","text":"Users with train/val/test: 8000\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Строим user-item матрицу только по train_hist (без val/test), чтобы избежать утечки будущего.\n# X_raw[u, it] = сколько train-корзин пользователя u содержали товар it (presence in basket).\nrows, cols, data = [], [], []\nfor u, baskets in train_hist.items():\n    c = Counter()\n    for b in baskets:\n        for it in set(b):   # presence in basket: учитываем товар один раз на корзину\n            c[it] += 1\n    for it, v in c.items():\n        rows.append(u)\n        cols.append(it)\n        data.append(float(v))\n\nX_raw = sparse.csr_matrix((data, (rows, cols)), shape=(n_users, n_items), dtype=np.float32)\n\n# L2-нормировка по пользователям для косинусной похожести:\n# cos(u,v) = dot(X_cos[u], X_cos[v])\nX_cos = normalize(X_raw, norm='l2', axis=1)\n\n# Разреженность матрицы: доля ненулевых элементов\ndensity = X_raw.nnz / (n_users * n_items)\nprint(\"X_raw nnz:\", X_raw.nnz, \"density:\", f\"{density:.6f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-20T11:31:06.613356Z","iopub.execute_input":"2025-12-20T11:31:06.613936Z","iopub.status.idle":"2025-12-20T11:31:06.882787Z","shell.execute_reply.started":"2025-12-20T11:31:06.613911Z","shell.execute_reply":"2025-12-20T11:31:06.882180Z"}},"outputs":[{"name":"stdout","text":"X_raw nnz: 226389 density: 0.001338\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import numpy as np\nfrom scipy import sparse\n\ndef build_x_bin_from_xraw(X_raw_csr):\n    Xb = X_raw_csr.copy().tocsr()\n    Xb.data = np.ones_like(Xb.data, dtype=np.float32)\n    return Xb\n\ndef topk_sorted_csr(mat_csr, k):\n    \"\"\"\n    Оставляет top-k элементов по значению в каждой строке CSR и сортирует их по убыванию.\n    \"\"\"\n    mat = mat_csr.tocsr()\n    indptr, indices, data = mat.indptr, mat.indices, mat.data\n\n    new_indptr = np.zeros(mat.shape[0] + 1, dtype=np.int32)\n    new_indices = []\n    new_data = []\n\n    nnz_so_far = 0\n    for i in range(mat.shape[0]):\n        start, end = indptr[i], indptr[i + 1]\n        row_idx = indices[start:end]\n        row_data = data[start:end]\n\n        if row_data.size == 0:\n            new_indptr[i + 1] = nnz_so_far\n            continue\n\n        if row_data.size > k:\n            top = np.argpartition(-row_data, k)[:k]\n            top = top[np.argsort(-row_data[top])]\n            row_idx = row_idx[top]\n            row_data = row_data[top]\n        else:\n            order = np.argsort(-row_data)\n            row_idx = row_idx[order]\n            row_data = row_data[order]\n\n        new_indices.extend(row_idx.tolist())\n        new_data.extend(row_data.astype(np.float32).tolist())\n        nnz_so_far += len(row_idx)\n        new_indptr[i + 1] = nnz_so_far\n\n    return sparse.csr_matrix(\n        (np.array(new_data, dtype=np.float32),\n         np.array(new_indices, dtype=np.int32),\n         new_indptr),\n        shape=mat.shape\n    )\n\ndef build_item_cosine_sim_topk(X_raw_csr, topk=100, use_binary=True):\n    \"\"\"\n    Строим item-item cosine similarity из train-матрицы:\n    - X_bin: user×item (0/1)\n    - C = X_bin.T @ X_bin: item×item co-occurrence по пользователям\n    - cosine: C_ij / (||i|| * ||j||)\n    - оставляем topk соседей на item\n    \"\"\"\n    Xb = build_x_bin_from_xraw(X_raw_csr) if use_binary else X_raw_csr.tocsr()\n    Xi = Xb.T.tocsr()  # item×user\n\n    norms = np.sqrt(np.asarray(Xi.multiply(Xi).sum(axis=1)).ravel()) + 1e-12\n\n    C = (Xi @ Xi.T).tocsr()\n    C.setdiag(0.0)\n    C.eliminate_zeros()\n\n    C = C.tocoo()\n    C.data = (C.data / (norms[C.row] * norms[C.col])).astype(np.float32)\n\n    S = C.tocsr()\n    S = topk_sorted_csr(S, topk)\n    return S\n\ndef itemknn_recommender_factory(X_user_csr, S_itemitem_csr, fallback_scores=None):\n    \"\"\"\n    score(u,:) = X_user[u] @ S_itemitem\n    Важно: результат dot(...) — sparse. Для topN строим плотный вектор корректно.\n    \"\"\"\n    n_items_local = S_itemitem_csr.shape[0]\n\n    # fallback лучше брать как item popularity по train, а не sum(S)\n    if fallback_scores is None:\n        fallback_scores = np.asarray(X_user_csr.sum(axis=0)).ravel().astype(np.float32)\n    else:\n        fallback_scores = np.asarray(fallback_scores).ravel().astype(np.float32)\n\n    def recommend(u, topn=TOPN_RECOMMEND):\n        x = X_user_csr[u]                 # 1×n_items (CSR)\n        tmp = x.dot(S_itemitem_csr)       # 1×n_items (sparse)\n\n        # корректная проверка \"всё нулевое\" для sparse\n        if tmp.nnz == 0:\n            scores = fallback_scores\n        else:\n            # делаем плотный вектор только по ненулевым индексам (быстрее, чем toarray())\n            tmp = tmp.tocsr()\n            scores = np.zeros(n_items_local, dtype=np.float32)\n            scores[tmp.indices] = tmp.data.astype(np.float32)\n\n        topn2 = min(topn, scores.shape[0])\n        idx = np.argpartition(-scores, topn2)[:topn2]\n        idx = idx[np.argsort(-scores[idx])]\n        return idx.tolist()\n\n    return recommend\n\n# строим item-item similarity и рекомендатель\nS_item_default = build_item_cosine_sim_topk(X_raw, topk=ITEMKNN_DEFAULT_K, use_binary=True)\nitemknn_rec = itemknn_recommender_factory(X_raw, S_item_default)\n\nprint(\"ItemKNN ready. S_item nnz:\", S_item_default.nnz)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-20T11:31:06.883596Z","iopub.execute_input":"2025-12-20T11:31:06.883889Z","iopub.status.idle":"2025-12-20T11:31:08.643269Z","shell.execute_reply.started":"2025-12-20T11:31:06.883854Z","shell.execute_reply":"2025-12-20T11:31:08.642594Z"}},"outputs":[{"name":"stdout","text":"ItemKNN ready. S_item nnz: 1669659\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"def build_item_item_graph(R, tau=2):\n    \"\"\"\n    R: csr_matrix (users x items)\n    tau: threshold\n    \"\"\"\n    # item-item co-occurrence\n    W = (R.T @ R).tocoo()\n    \n    mask = (W.row != W.col) & (W.data >= tau)\n    edges = np.vstack([W.row[mask], W.col[mask]]).T\n    \n    return edges\n\nedges = build_item_item_graph(X_raw, tau=2)\nprint(f\"Num edges: {len(edges)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-20T11:31:08.644071Z","iopub.execute_input":"2025-12-20T11:31:08.644464Z","iopub.status.idle":"2025-12-20T11:31:09.008864Z","shell.execute_reply.started":"2025-12-20T11:31:08.644430Z","shell.execute_reply":"2025-12-20T11:31:09.008270Z"}},"outputs":[{"name":"stdout","text":"Num edges: 3323524\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"def poincare_distance(x, y):\n    x2 = (x * x).sum(dim=-1)\n    y2 = (y * y).sum(dim=-1)\n    diff2 = ((x - y) ** 2).sum(dim=-1)\n\n    denom = (1 - x2) * (1 - y2)\n    z = 1 + 2 * diff2 / denom.clamp_min(EPS)\n\n    return torch.acosh(z.clamp_min(1 + EPS))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-20T11:31:09.009940Z","iopub.execute_input":"2025-12-20T11:31:09.010353Z","iopub.status.idle":"2025-12-20T11:31:09.014435Z","shell.execute_reply.started":"2025-12-20T11:31:09.010330Z","shell.execute_reply":"2025-12-20T11:31:09.013727Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def project_to_ball(x, eps=1e-5):\n    norm = torch.norm(x, dim=-1, keepdim=True)\n    max_norm = 1 - eps\n    return x / norm.clamp_min(EPS) * torch.clamp(norm, max=max_norm)\n\n\nclass PoincareEmbedding(nn.Module):\n    def __init__(self, num_items, dim):\n        super().__init__()\n        self.emb = nn.Embedding(num_items, dim)\n        nn.init.uniform_(self.emb.weight, -1e-3, 1e-3)\n\n    \n    def forward(self, idx):\n        return project_to_ball(self.emb(idx))\n\n\ndef poincare_loss(model, i, j, negs):\n    \"\"\"\n    i: (B,)\n    j: (B,)\n    negs: (B, K)\n    \"\"\"\n    xi = model(i)              # (B, d)\n    xj = model(j)              # (B, d)\n    xk = model(negs)           # (B, K, d)\n\n    d_pos = poincare_distance(xi, xj)               # (B,)\n    d_neg = poincare_distance(\n        xi.unsqueeze(1), xk\n    )                                                # (B, K)\n\n    numerator = torch.exp(-d_pos)\n    denominator = torch.exp(-d_neg).sum(dim=1)\n\n    loss = -torch.log(numerator / denominator.clamp_min(EPS))\n    return loss.mean()\n\n\ndef sample_negatives(batch_size, num_items, K):\n    return torch.randint(\n        low=0,\n        high=num_items,\n        size=(batch_size, K)\n    )\n\n\ndef train_poincare(edges,\n                   num_items,\n                   dim=10,\n                   epochs=10,\n                   batch_size=256,\n                   lr=0.05,\n                   neg_k=10,\n                   device=\"cpu\"):\n    model = PoincareEmbedding(num_items, dim).to(device)\n    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n    edges = torch.tensor(edges, dtype=torch.long)\n    for epoch in range(epochs):\n        perm = torch.randperm(len(edges))\n        total_loss = 0.0\n\n        for idx in tqdm(range(0, len(edges), batch_size)):\n            batch_idx = perm[idx:idx + batch_size]\n            batch = edges[batch_idx]\n\n            i = batch[:, 0].to(device)\n            j = batch[:, 1].to(device)\n            negs = sample_negatives(len(i), num_items, neg_k).to(device)\n\n            optimizer.zero_grad()\n            loss = poincare_loss(model, i, j, negs)\n            loss.backward()\n            optimizer.step()\n\n            # ОБЯЗАТЕЛЬНО: проекция\n            with torch.no_grad():\n                model.emb.weight.copy_(\n                    project_to_ball(model.emb.weight)\n                )\n\n            total_loss += loss.item() * len(i)\n\n        print(f\"Epoch {epoch+1}: loss = {total_loss / len(edges):.4f}\")\n\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-20T11:31:09.016111Z","iopub.execute_input":"2025-12-20T11:31:09.016401Z","iopub.status.idle":"2025-12-20T11:31:09.028067Z","shell.execute_reply.started":"2025-12-20T11:31:09.016382Z","shell.execute_reply":"2025-12-20T11:31:09.027452Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"model = train_poincare(\n    edges=edges,\n    num_items=X_raw.shape[1],\n    dim=20,\n    epochs=50,\n    batch_size=1024,\n    lr=0.05,\n    neg_k=15,\n    device='cuda'\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"@torch.no_grad()\ndef pairwise_poincare_dist(emb):\n    x = emb.unsqueeze(1)\n    y = emb.unsqueeze(0)\n    return poincare_distance(x, y)\n\n\n@torch.no_grad()\ndef knn_poincare(model, k=10):\n    emb = model.emb.weight\n    dist = pairwise_poincare_dist(emb)\n    knn = torch.topk(dist, k=k+1, largest=False).indices[:, 1:]\n    return knn\n\n\ndef build_item_poincare_knn(model, topk=100, device=\"cpu\"):\n    with torch.no_grad():\n        emb = model.emb.weight.to(device)  # (n_items, d)\n        n = emb.shape[0]\n\n        rows, cols, data = [], [], []\n\n        for i in range(n):\n            xi = emb[i].unsqueeze(0)\n            d = poincare_distance(xi, emb).cpu().numpy()\n            d[i] = np.inf\n\n            idx = np.argpartition(d, topk)[:topk]\n            idx = idx[np.argsort(d[idx])]\n\n            rows.extend([i] * len(idx))\n            cols.extend(idx.tolist())\n            data.extend(np.exp(-d[idx]).astype(np.float32))\n\n    return sparse.csr_matrix(\n        (data, (rows, cols)),\n        shape=(n, n)\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-20T11:45:24.969751Z","iopub.execute_input":"2025-12-20T11:45:24.970445Z","iopub.status.idle":"2025-12-20T11:45:24.977317Z","shell.execute_reply.started":"2025-12-20T11:45:24.970416Z","shell.execute_reply":"2025-12-20T11:45:24.976546Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"S_itemitem_hyperbolic = build_item_poincare_knn(\n    model,\n    topk=ITEMKNN_DEFAULT_K\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-20T11:45:27.358955Z","iopub.execute_input":"2025-12-20T11:45:27.359639Z","iopub.status.idle":"2025-12-20T11:45:57.134751Z","shell.execute_reply.started":"2025-12-20T11:45:27.359610Z","shell.execute_reply":"2025-12-20T11:45:57.134159Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"itemknn_hyper = itemknn_recommender_factory(\n    X_raw,\n    S_itemitem_hyperbolic\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-20T11:45:57.135952Z","iopub.execute_input":"2025-12-20T11:45:57.136183Z","iopub.status.idle":"2025-12-20T11:45:57.140511Z","shell.execute_reply.started":"2025-12-20T11:45:57.136162Z","shell.execute_reply":"2025-12-20T11:45:57.139729Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"def recall_at_k(pred_items, true_items, k):\n    \"\"\"\n    Recall@K = доля товаров из истинной корзины, которые попали в top-K рекомендаций.\n    true_items: список товаров в истинной корзине (val/test)\n    pred_items: ранжированный список рекомендаций\n    \"\"\"\n    pred_k = pred_items[:k]\n    true_set = set(true_items)\n    if len(true_set) == 0:\n        return 0.0\n    return len(set(pred_k) & true_set) / len(true_set)\n\ndef ndcg_at_k(pred_items, true_items, k):\n    \"\"\"\n    NDCG@K учитывает порядок: попадания в верхние позиции оцениваются выше.\n    Здесь релевантность бинарная: товар релевантен, если он есть в true_items.\n    \"\"\"\n    true_set = set(true_items)\n    pred_k = pred_items[:k]\n\n    # DCG\n    dcg = 0.0\n    for i, it in enumerate(pred_k):\n        if it in true_set:\n            dcg += 1.0 / np.log2(i + 2)  # i=0 -> log2(2)=1\n\n    # IDCG: максимум возможного DCG при идеальном ранжировании\n    ideal_hits = min(k, len(true_set))\n    idcg = sum(1.0 / np.log2(i + 2) for i in range(ideal_hits))\n\n    return dcg / idcg if idcg > 0 else 0.0\n\ndef evaluate_model(recommender_fn, users, true_baskets, topk_list=(5,10,20)):\n    \"\"\"\n    Оцениваем модель на пользователях:\n    - recommender_fn(u) должен возвращать ранжированный список item_id (индексы товаров)\n    - true_baskets[u] — истинная корзина (список item_id)\n    Возвращаем средние Recall@K и NDCG@K по пользователям для каждого K.\n    \"\"\"\n    rows = []\n    for u in users:\n        u = int(u)\n        pred = recommender_fn(u)\n        true = true_baskets[u]\n        for k in topk_list:\n            rows.append({\n                \"u\": u,\n                \"k\": int(k),\n                \"recall\": recall_at_k(pred, true, k),\n                \"ndcg\": ndcg_at_k(pred, true, k),\n            })\n\n    return (pd.DataFrame(rows)\n            .groupby(\"k\")[[\"recall\",\"ndcg\"]].mean()\n            .reset_index())\n\ndef tag_result(df_res, model_name, split_name):\n    \"\"\"Добавляем метаданные (название модели и сплит) к таблице метрик.\"\"\"\n    out = df_res.copy()\n    out[\"model\"] = model_name\n    out[\"split\"] = split_name\n    return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-20T11:47:44.658977Z","iopub.execute_input":"2025-12-20T11:47:44.659559Z","iopub.status.idle":"2025-12-20T11:47:44.668251Z","shell.execute_reply.started":"2025-12-20T11:47:44.659528Z","shell.execute_reply":"2025-12-20T11:47:44.667610Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"users_val = np.array(sorted(val_basket.keys()))\nprint(\"VAL users:\", len(users_val))\n\nres_itemknn_hyper_val = evaluate_model(\n    lambda u: itemknn_hyper(u, TOPN_RECOMMEND),\n    users_val,\n    val_basket,\n    TOPK_LIST\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-20T11:48:04.767567Z","iopub.execute_input":"2025-12-20T11:48:04.767852Z","iopub.status.idle":"2025-12-20T11:48:07.501981Z","shell.execute_reply.started":"2025-12-20T11:48:04.767827Z","shell.execute_reply":"2025-12-20T11:48:07.501440Z"}},"outputs":[{"name":"stdout","text":"VAL users: 8000\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"val_table_default = pd.concat([\n    tag_result(res_itemknn_hyper_val, f\"ItemKNN(topk={ITEMKNN_DEFAULT_K})\", \"val\"),\n], ignore_index=True)\n\nval_table_default","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-20T09:55:34.668389Z","iopub.execute_input":"2025-12-20T09:55:34.668712Z","iopub.status.idle":"2025-12-20T09:55:34.682120Z","shell.execute_reply.started":"2025-12-20T09:55:34.668685Z","shell.execute_reply":"2025-12-20T09:55:34.681123Z"}},"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"    k    recall      ndcg              model split\n0   5  0.004724  0.006389  ItemKNN(topk=100)   val\n1  10  0.007398  0.007137  ItemKNN(topk=100)   val\n2  20  0.014564  0.009663  ItemKNN(topk=100)   val","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>k</th>\n      <th>recall</th>\n      <th>ndcg</th>\n      <th>model</th>\n      <th>split</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5</td>\n      <td>0.004724</td>\n      <td>0.006389</td>\n      <td>ItemKNN(topk=100)</td>\n      <td>val</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10</td>\n      <td>0.007398</td>\n      <td>0.007137</td>\n      <td>ItemKNN(topk=100)</td>\n      <td>val</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20</td>\n      <td>0.014564</td>\n      <td>0.009663</td>\n      <td>ItemKNN(topk=100)</td>\n      <td>val</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":50},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}