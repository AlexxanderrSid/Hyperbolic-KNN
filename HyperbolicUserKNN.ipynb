{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":29446,"sourceType":"datasetVersion","datasetId":22987}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nimport scipy.sparse as sp\nfrom tqdm import tqdm\n\nEPS = 1e-5","metadata":{"execution":{"iopub.status.busy":"2025-12-21T21:45:44.277039Z","iopub.execute_input":"2025-12-21T21:45:44.277327Z","iopub.status.idle":"2025-12-21T21:45:48.566785Z","shell.execute_reply.started":"2025-12-21T21:45:44.277297Z","shell.execute_reply":"2025-12-21T21:45:48.563537Z"},"trusted":true},"outputs":[],"execution_count":1},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Импорты и глобальная конфигурация\nimport os, glob, math, pickle, time\nfrom collections import defaultdict, Counter\n\nimport numpy as np\nimport pandas as pd\n\nfrom scipy import sparse\nfrom sklearn.preprocessing import normalize\nfrom sklearn.decomposition import TruncatedSVD\n\nimport matplotlib.pyplot as plt\n\nRANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)\n\n# --- Fast dev mode ---\nDEV_MODE = True\nMAX_USERS = 8000 if DEV_MODE else None  # None для полного прогона\n\nMIN_BASKETS_PER_USER = 3  # должно быть >= 3, чтобы можно было сделать train/val/test\n\n# ---Метрики и размер списка рекомендаций---\nTOPK_LIST = [5, 10, 20]\nTOPN_RECOMMEND = 200  # внутренняя длина списка кандидатов (сколько объектов ранжируем)\n\n\n# --- UserKNN ---\nUSERKNN_TUNE_GRID = [50, 100, 200, 500]  # значения числа соседей для подбора\nUSERKNN_DEFAULT_K = 200\n\n# --- TIFU-KNN(simple) ---\nTIFU_GROUPS_GRID = [5, 7]              # варианты числа групп истории\nTIFU_ALPHA_GRID = [0.5, 0.7, 0.9]      # варианты смешивания PIF/IU\nTIFU_NEIGHBORS_GRID = [100, 300]       # варианты числа соседей\n\n# --- ItemKNN (добавляем, чтобы \"KNN baseline\" был однозначно покрыт) ---\nITEMKNN_TUNE_GRID = [50, 100, 200]   # сколько похожих items хранить на item (topK)\nITEMKNN_DEFAULT_K = 100\n\n\nTIFU_WITHIN_DECAY = 0.9  # затухание внутри группы\nTIFU_GROUP_DECAY = 0.7   # затухание между группами\nTIFU_DEFAULT_GROUPS = 7\nTIFU_DEFAULT_ALPHA = 0.7\nTIFU_DEFAULT_K = 300\n\nprint(\"DEV_MODE:\", DEV_MODE, \"MAX_USERS:\", MAX_USERS)\n\ndef find_csv_candidate():\n    # Ищем CSV-файлы в папке Kaggle input\n    cands = glob.glob('/kaggle/input/*/*.csv') + glob.glob('/kaggle/input/*/*.CSV')\n    if not cands:\n        raise FileNotFoundError('В /kaggle/input не найдены CSV. Проверьте, что датасет добавлен в ноутбук.')\n\n    # Предпочитаем файл, который похож на Ta-Feng по названию\n    for p in cands:\n        low = p.lower()\n        if ('ta' in low and 'feng' in low) or ('tafeng' in low):\n            return p\n\n    # Если не нашли — берём самый большой CSV (как запасной вариант)\n    cands = sorted(cands, key=lambda p: os.path.getsize(p), reverse=True)\n    return cands[0]\n\ndef detect_columns(df: pd.DataFrame):\n    cols = {c.lower(): c for c in df.columns}\n\n    def pick(candidates):\n        for c in candidates:\n            if c in cols:\n                return cols[c]\n        return None\n\n    user_col = pick(['customer_id', 'cust_id', 'user_id', 'userid', 'member_id', 'client_id'])\n    item_col = pick(['product_id', 'item_id', 'prod_id', 'sku_id', 'article_id'])\n    date_col = pick(['transaction_dt', 'trans_date', 'date', 't_dat', 'datetime', 'transaction_date'])\n\n    # В Ta-Feng часто встречаются имена в верхнем регистре: CUSTOMER_ID, PRODUCT_ID, TRANSACTION_DT\n    if user_col is None:\n        for c in df.columns:\n            if c.upper() == 'CUSTOMER_ID':\n                user_col = c\n                break\n    if item_col is None:\n        for c in df.columns:\n            if c.upper() == 'PRODUCT_ID':\n                item_col = c\n                break\n    if date_col is None:\n        for c in df.columns:\n            if c.upper() == 'TRANSACTION_DT':\n                date_col = c\n                break\n\n    return user_col, item_col, date_col\n\npath = find_csv_candidate()\nprint(\"Using CSV:\", path)\n\ndf = pd.read_csv(path)\nprint(\"Shape:\", df.shape)\nprint(\"Columns:\", list(df.columns)[:30])\n\nuser_col, item_col, date_col = detect_columns(df)\nprint(\"Detected columns:\", {\"user_col\": user_col, \"item_col\": item_col, \"date_col\": date_col})\n\nif user_col is None or item_col is None or date_col is None:\n    raise ValueError(\n        \"Не удалось автоматически определить необходимые колонки. \"\n        \"Пожалуйста, задайте user_col/item_col/date_col вручную после просмотра df.columns.\"\n    )\n","metadata":{"execution":{"iopub.status.busy":"2025-12-21T21:45:48.568279Z","iopub.execute_input":"2025-12-21T21:45:48.571768Z","iopub.status.idle":"2025-12-21T21:45:50.394354Z","shell.execute_reply.started":"2025-12-21T21:45:48.571734Z","shell.execute_reply":"2025-12-21T21:45:50.393749Z"},"trusted":true},"outputs":[{"name":"stdout","text":"DEV_MODE: True MAX_USERS: 8000\nUsing CSV: /kaggle/input/ta-feng-grocery-dataset/ta_feng_all_months_merged.csv\nShape: (817741, 9)\nColumns: ['TRANSACTION_DT', 'CUSTOMER_ID', 'AGE_GROUP', 'PIN_CODE', 'PRODUCT_SUBCLASS', 'PRODUCT_ID', 'AMOUNT', 'ASSET', 'SALES_PRICE']\nDetected columns: {'user_col': 'CUSTOMER_ID', 'item_col': 'PRODUCT_ID', 'date_col': 'TRANSACTION_DT'}\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Приводим типы к строкам (важно, чтобы не потерять ведущие нули в идентификаторах)\ndf[user_col] = df[user_col].astype(str)\ndf[item_col] = df[item_col].astype(str)\n\n# Парсим дату, некорректные строки превращаются в NaT\ndf[date_col] = pd.to_datetime(df[date_col], errors='coerce')\n\n# Удаляем строки без даты/пользователя/товара\ndf = df.dropna(subset=[date_col, user_col, item_col]).copy()\n\n# Округляем datetime вниз до даты (без времени)\ndf['__date'] = df[date_col].dt.floor('D')\n\n# Группировка в корзины\nbasket_df = (\n    df.groupby([user_col, '__date'])[item_col]\n      .apply(lambda s: list(pd.unique(s)))   # уникальные товары в корзине\n      .reset_index()\n      .rename(columns={user_col: 'user_raw', '__date': 'date', item_col: 'items_raw'})\n)\n\nbasket_df = basket_df.sort_values(['user_raw', 'date']).reset_index(drop=True)\nprint(\"Baskets:\", basket_df.shape, \"Unique users:\", basket_df['user_raw'].nunique())\nbasket_df.head()","metadata":{"execution":{"iopub.status.busy":"2025-12-21T21:45:50.395127Z","iopub.execute_input":"2025-12-21T21:45:50.395369Z","iopub.status.idle":"2025-12-21T21:45:57.399403Z","shell.execute_reply.started":"2025-12-21T21:45:50.395336Z","shell.execute_reply":"2025-12-21T21:45:57.398782Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Baskets: (119578, 3) Unique users: 32266\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"  user_raw       date                                          items_raw\n0   100021 2000-11-03  [9310042571491, 4719783004070, 4711049230223, ...\n1   100021 2000-11-05  [4710018004605, 4719111020109, 4710247005299, ...\n2   100021 2000-11-19  [4711686002016, 47106710, 4711686002528, 47102...\n3   100021 2000-11-28  [4711800531385, 4714981010038, 4710339772139, ...\n4   100021 2000-12-02  [4710088436511, 4710094014741, 4710105045443, ...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_raw</th>\n      <th>date</th>\n      <th>items_raw</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>100021</td>\n      <td>2000-11-03</td>\n      <td>[9310042571491, 4719783004070, 4711049230223, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>100021</td>\n      <td>2000-11-05</td>\n      <td>[4710018004605, 4719111020109, 4710247005299, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>100021</td>\n      <td>2000-11-19</td>\n      <td>[4711686002016, 47106710, 4711686002528, 47102...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>100021</td>\n      <td>2000-11-28</td>\n      <td>[4711800531385, 4714981010038, 4710339772139, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>100021</td>\n      <td>2000-12-02</td>\n      <td>[4710088436511, 4710094014741, 4710105045443, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"from collections import defaultdict\nimport numpy as np\nimport pandas as pd\n\n# Фильтруем пользователей с достаточным числом корзин:\n#    нам нужно минимум 3 корзины на пользователя, чтобы сформировать train/val/test\ncounts = basket_df.groupby('user_raw').size()\nkeep_users = counts[counts >= MIN_BASKETS_PER_USER].index\nbasket_df = basket_df[basket_df['user_raw'].isin(keep_users)].copy()\n\n# Опционально: режим разработки (dev).\n#    Если задан MAX_USERS, берём только первых N пользователей (после сортировки/порядка появления).\n#    Это ускоряет эксперименты и отладку в Kaggle.\nif MAX_USERS is not None:\n    users = basket_df['user_raw'].unique()[:MAX_USERS]\n    basket_df = basket_df[basket_df['user_raw'].isin(users)].copy()\n\n# На всякий случай пересортируем по пользователю и времени,\n#    чтобы дальнейший split по времени был корректным\nbasket_df = basket_df.sort_values(['user_raw', 'date']).reset_index(drop=True)\nprint(\"After filter/dev: baskets\", basket_df.shape, \"users\", basket_df['user_raw'].nunique())\n\n# Маппинг сырого user/item ID в индексы 0..n-1\n#    Это нужно для эффективной работы с матрицами (scipy.sparse) и моделями.\nuser_ids = basket_df['user_raw'].unique()\nitem_ids = pd.unique(np.concatenate(basket_df['items_raw'].values))\n\nuser2idx = {u: i for i, u in enumerate(user_ids)}\nitem2idx = {it: i for i, it in enumerate(item_ids)}\n\n# обратные отображения (удобно для дебага/вывода рекомендаций)\nidx2user = {i: u for u, i in user2idx.items()}\nidx2item = {i: it for it, i in item2idx.items()}\n\n# 5) Добавляем индекс пользователя и переводим списки товаров в список индексов\nbasket_df['u'] = basket_df['user_raw'].map(user2idx)\nbasket_df['item_idx_list'] = basket_df['items_raw'].apply(lambda xs: [item2idx[x] for x in xs])\n\nn_users = len(user2idx)\nn_items = len(item2idx)\nprint(\"n_users:\", n_users, \"n_items:\", n_items)\n\ndisplay(basket_df.head())","metadata":{"execution":{"iopub.status.busy":"2025-12-21T21:45:57.400342Z","iopub.execute_input":"2025-12-21T21:45:57.400650Z","iopub.status.idle":"2025-12-21T21:45:57.827817Z","shell.execute_reply.started":"2025-12-21T21:45:57.400617Z","shell.execute_reply":"2025-12-21T21:45:57.827192Z"},"trusted":true},"outputs":[{"name":"stdout","text":"After filter/dev: baskets (53734, 3) users 8000\nn_users: 8000 n_items: 21149\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  user_raw       date                                          items_raw  u  \\\n0   100021 2000-11-03  [9310042571491, 4719783004070, 4711049230223, ...  0   \n1   100021 2000-11-05  [4710018004605, 4719111020109, 4710247005299, ...  0   \n2   100021 2000-11-19  [4711686002016, 47106710, 4711686002528, 47102...  0   \n3   100021 2000-11-28  [4711800531385, 4714981010038, 4710339772139, ...  0   \n4   100021 2000-12-02  [4710088436511, 4710094014741, 4710105045443, ...  0   \n\n                                      item_idx_list  \n0                                [0, 1, 2, 3, 4, 5]  \n1              [6, 7, 8, 9, 10, 11, 12, 13, 14, 15]  \n2  [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27]  \n3      [28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]  \n4                              [32, 39, 20, 40, 41]  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_raw</th>\n      <th>date</th>\n      <th>items_raw</th>\n      <th>u</th>\n      <th>item_idx_list</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>100021</td>\n      <td>2000-11-03</td>\n      <td>[9310042571491, 4719783004070, 4711049230223, ...</td>\n      <td>0</td>\n      <td>[0, 1, 2, 3, 4, 5]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>100021</td>\n      <td>2000-11-05</td>\n      <td>[4710018004605, 4719111020109, 4710247005299, ...</td>\n      <td>0</td>\n      <td>[6, 7, 8, 9, 10, 11, 12, 13, 14, 15]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>100021</td>\n      <td>2000-11-19</td>\n      <td>[4711686002016, 47106710, 4711686002528, 47102...</td>\n      <td>0</td>\n      <td>[16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>100021</td>\n      <td>2000-11-28</td>\n      <td>[4711800531385, 4714981010038, 4710339772139, ...</td>\n      <td>0</td>\n      <td>[28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>100021</td>\n      <td>2000-12-02</td>\n      <td>[4710088436511, 4710094014741, 4710105045443, ...</td>\n      <td>0</td>\n      <td>[32, 39, 20, 40, 41]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"user_baskets = defaultdict(list)  # u -> list of (date, [items])\nfor row in basket_df.itertuples(index=False):\n    user_baskets[row.u].append((row.date, row.item_idx_list))\n\n# Гарантируем сортировку по времени (вдруг где-то нарушилась)\nfor u in user_baskets:\n    user_baskets[u] = sorted(user_baskets[u], key=lambda x: x[0])\n\ntrain_hist = {}\nval_basket = {}\ntest_basket = {}\n\nfor u, seq in user_baskets.items():\n    baskets = [b for _, b in seq]\n    # На всякий случай проверяем минимальную длину\n    if len(baskets) < 3:\n        continue\n    train_hist[u] = baskets[:-2]   # все корзины, кроме двух последних\n    val_basket[u]  = baskets[-2]   # предпоследняя корзина\n    test_basket[u] = baskets[-1]   # последняя корзина\n\nprint(\"Users with train/val/test:\", len(train_hist))\nassert len(train_hist) > 0, \"No users available after filtering/splitting.\"","metadata":{"execution":{"iopub.status.busy":"2025-12-21T21:45:57.828651Z","iopub.execute_input":"2025-12-21T21:45:57.828873Z","iopub.status.idle":"2025-12-21T21:45:58.147073Z","shell.execute_reply.started":"2025-12-21T21:45:57.828851Z","shell.execute_reply":"2025-12-21T21:45:58.146276Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Users with train/val/test: 8000\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Строим user-item матрицу только по train_hist (без val/test), чтобы избежать утечки будущего.\n# X_raw[u, it] = сколько train-корзин пользователя u содержали товар it (presence in basket).\nrows, cols, data = [], [], []\nfor u, baskets in train_hist.items():\n    c = Counter()\n    for b in baskets:\n        for it in set(b):   # presence in basket: учитываем товар один раз на корзину\n            c[it] += 1\n    for it, v in c.items():\n        rows.append(u)\n        cols.append(it)\n        data.append(float(v))\n\nX_raw = sparse.csr_matrix((data, (rows, cols)), shape=(n_users, n_items), dtype=np.float32)\n\n# L2-нормировка по пользователям для косинусной похожести:\n# cos(u,v) = dot(X_cos[u], X_cos[v])\nX_cos = normalize(X_raw, norm='l2', axis=1)\n\n# Разреженность матрицы: доля ненулевых элементов\ndensity = X_raw.nnz / (n_users * n_items)\nprint(\"X_raw nnz:\", X_raw.nnz, \"density:\", f\"{density:.6f}\")","metadata":{"execution":{"iopub.status.busy":"2025-12-21T21:45:58.148056Z","iopub.execute_input":"2025-12-21T21:45:58.148418Z","iopub.status.idle":"2025-12-21T21:45:58.427709Z","shell.execute_reply.started":"2025-12-21T21:45:58.148384Z","shell.execute_reply":"2025-12-21T21:45:58.426923Z"},"trusted":true},"outputs":[{"name":"stdout","text":"X_raw nnz: 226389 density: 0.001338\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import numpy as np\nfrom scipy import sparse\n\ndef build_x_bin_from_xraw(X_raw_csr):\n    Xb = X_raw_csr.copy().tocsr()\n    Xb.data = np.ones_like(Xb.data, dtype=np.float32)\n    return Xb\n\ndef topk_sorted_csr(mat_csr, k):\n    \"\"\"\n    Оставляет top-k элементов по значению в каждой строке CSR и сортирует их по убыванию.\n    \"\"\"\n    mat = mat_csr.tocsr()\n    indptr, indices, data = mat.indptr, mat.indices, mat.data\n\n    new_indptr = np.zeros(mat.shape[0] + 1, dtype=np.int32)\n    new_indices = []\n    new_data = []\n\n    nnz_so_far = 0\n    for i in range(mat.shape[0]):\n        start, end = indptr[i], indptr[i + 1]\n        row_idx = indices[start:end]\n        row_data = data[start:end]\n\n        if row_data.size == 0:\n            new_indptr[i + 1] = nnz_so_far\n            continue\n\n        if row_data.size > k:\n            top = np.argpartition(-row_data, k)[:k]\n            top = top[np.argsort(-row_data[top])]\n            row_idx = row_idx[top]\n            row_data = row_data[top]\n        else:\n            order = np.argsort(-row_data)\n            row_idx = row_idx[order]\n            row_data = row_data[order]\n\n        new_indices.extend(row_idx.tolist())\n        new_data.extend(row_data.astype(np.float32).tolist())\n        nnz_so_far += len(row_idx)\n        new_indptr[i + 1] = nnz_so_far\n\n    return sparse.csr_matrix(\n        (np.array(new_data, dtype=np.float32),\n         np.array(new_indices, dtype=np.int32),\n         new_indptr),\n        shape=mat.shape\n    )\n\ndef build_item_cosine_sim_topk(X_raw_csr, topk=100, use_binary=True):\n    \"\"\"\n    Строим item-item cosine similarity из train-матрицы:\n    - X_bin: user×item (0/1)\n    - C = X_bin.T @ X_bin: item×item co-occurrence по пользователям\n    - cosine: C_ij / (||i|| * ||j||)\n    - оставляем topk соседей на item\n    \"\"\"\n    Xb = build_x_bin_from_xraw(X_raw_csr) if use_binary else X_raw_csr.tocsr()\n    Xi = Xb.T.tocsr()  # item×user\n\n    norms = np.sqrt(np.asarray(Xi.multiply(Xi).sum(axis=1)).ravel()) + 1e-12\n\n    C = (Xi @ Xi.T).tocsr()\n    C.setdiag(0.0)\n    C.eliminate_zeros()\n\n    C = C.tocoo()\n    C.data = (C.data / (norms[C.row] * norms[C.col])).astype(np.float32)\n\n    S = C.tocsr()\n    S = topk_sorted_csr(S, topk)\n    return S\n\ndef userknn_recommender_factory(X_train_csr, S_useruser_csr, fallback_scores=None):\n    n_items_local = X_train_csr.shape[1]\n\n    if fallback_scores is None:\n        fallback_scores = np.asarray(X_train_csr.sum(axis=0)).ravel().astype(np.float32)\n    else:\n        fallback_scores = np.asarray(fallback_scores).ravel().astype(np.float32)\n\n    def recommend(u, topn=TOPN_RECOMMEND):\n        sim_users = S_useruser_csr[u] \n        \n        tmp = sim_users.dot(X_train_csr)\n\n        if tmp.nnz == 0:\n            scores = fallback_scores\n        else:\n            tmp = tmp.tocsr()\n            scores = np.zeros(n_items_local, dtype=np.float32)\n            scores[tmp.indices] = tmp.data.astype(np.float32)\n            \n\n        topn2 = min(topn, scores.shape[0])\n        idx = np.argpartition(-scores, topn2)[:topn2]\n        idx = idx[np.argsort(-scores[idx])]\n        return idx.tolist()\n\n    return recommend\n","metadata":{"execution":{"iopub.status.busy":"2025-12-21T21:45:58.429934Z","iopub.execute_input":"2025-12-21T21:45:58.430173Z","iopub.status.idle":"2025-12-21T21:45:58.446131Z","shell.execute_reply.started":"2025-12-21T21:45:58.430151Z","shell.execute_reply":"2025-12-21T21:45:58.445432Z"},"trusted":true},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def build_user_user_graph(R, tau=2):\n    W = (R @ R.T).tocoo()\n    \n    mask = (W.row != W.col) & (W.data >= tau)\n    edges = np.vstack([W.row[mask], W.col[mask]]).T\n    \n    return edges\n\n\nuser_edges = build_user_user_graph(X_raw, tau=2)\nprint(f\"Num user edges: {len(user_edges)}\")","metadata":{"execution":{"iopub.status.busy":"2025-12-21T21:45:58.446837Z","iopub.execute_input":"2025-12-21T21:45:58.447216Z","iopub.status.idle":"2025-12-21T21:45:59.032768Z","shell.execute_reply.started":"2025-12-21T21:45:58.447151Z","shell.execute_reply":"2025-12-21T21:45:59.031973Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Num user edges: 6259612\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom tqdm import tqdm\n\nEPS = 1e-5\n\nclass PoincareEmbedding(nn.Module):\n    \n    def __init__(self, num_items, dim):\n        super().__init__()\n        self.emb = nn.Embedding(num_items, dim)\n        nn.init.uniform_(self.emb.weight, -1e-3, 1e-3)\n\n    def forward(self, idx):\n        return self.project_to_ball(self.emb(idx))\n    \n    def project_to_ball(self, x, eps=EPS):\n        norm = torch.norm(x, dim=-1, keepdim=True)\n        max_norm = 1 - eps\n        return x / norm.clamp_min(EPS) * torch.clamp(norm, max=max_norm)\n    \n    def poincare_distance(self, x, y):\n        x2 = (x * x).sum(dim=-1)\n        y2 = (y * y).sum(dim=-1)\n        diff2 = ((x - y) ** 2).sum(dim=-1)\n        denom = (1 - x2) * (1 - y2)\n        z = 1 + 2 * diff2 / denom.clamp_min(EPS)\n        return torch.acosh(z.clamp_min(1 + EPS))\n    \n    def sample_negatives(self, batch_size, num_items, K):\n        return torch.randint(low=0, high=num_items, size=(batch_size, K))\n    \n    def poincare_loss(self, i, j, negs):\n        xi = self.forward(i)\n        xj = self.forward(j)\n        xk = self.forward(negs)\n    \n        d_pos = self.poincare_distance(xi, xj)\n        d_neg = self.poincare_distance(xi.unsqueeze(1), xk)\n    \n        numerator = torch.exp(-d_pos)\n        denominator = torch.exp(-d_neg).sum(dim=1)\n    \n        loss = -torch.log(numerator / denominator.clamp_min(EPS))\n        return loss.mean()\n    \n    def train_embedding(self, edges, num_items, optimizer, epochs=10, batch_size=256, neg_k=10, device=\"cpu\"):\n        self.to(device)\n        edges = torch.tensor(edges, dtype=torch.long, device=device)\n        \n        for epoch in range(epochs):\n            perm = torch.randperm(len(edges), device=device)\n            total_loss = 0.0\n    \n            for idx in range(0, len(edges), batch_size):\n                batch_idx = perm[idx:idx + batch_size]\n                batch = edges[batch_idx]\n    \n                i = batch[:, 0]\n                j = batch[:, 1]\n                negs = self.sample_negatives(len(i), num_items, neg_k).to(device)\n    \n                optimizer.zero_grad()\n                loss = self.poincare_loss(i, j, negs)\n                loss.backward()\n                optimizer.step()\n    \n                with torch.no_grad():\n                    self.emb.weight.copy_(self.project_to_ball(self.emb.weight))\n    \n                total_loss += loss.item() * len(i)\n    \n            print(f\"Epoch {epoch+1}: loss = {total_loss / len(edges):.4f}\")\n        \n        return self","metadata":{"execution":{"iopub.status.busy":"2025-12-21T21:45:59.033683Z","iopub.execute_input":"2025-12-21T21:45:59.034080Z","iopub.status.idle":"2025-12-21T21:45:59.046376Z","shell.execute_reply.started":"2025-12-21T21:45:59.034040Z","shell.execute_reply":"2025-12-21T21:45:59.045435Z"},"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"code","source":"num_users = X_raw.shape[0]\ndim = 30\nlr = 0.001\n\nuser_model = PoincareEmbedding(num_users, dim)\nuser_optimizer = torch.optim.Adam(user_model.parameters(), lr=lr)\n\nuser_model.train_embedding(\n    edges=user_edges,\n    num_items=num_users,  \n    optimizer=user_optimizer,\n    epochs=50,             \n    batch_size=1024,\n    neg_k=15,\n    device='cuda' if torch.cuda.is_available() else 'cpu'\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-21T21:45:59.047338Z","iopub.execute_input":"2025-12-21T21:45:59.047627Z","iopub.status.idle":"2025-12-21T22:07:33.658344Z","shell.execute_reply.started":"2025-12-21T21:45:59.047598Z","shell.execute_reply":"2025-12-21T22:07:33.657714Z"}},"outputs":[{"name":"stdout","text":"Epoch 1: loss = 2.1466\nEpoch 2: loss = 2.0790\nEpoch 3: loss = 2.0827\nEpoch 4: loss = 2.0734\nEpoch 5: loss = 2.0620\nEpoch 6: loss = 2.0595\nEpoch 7: loss = 2.0523\nEpoch 8: loss = 2.0506\nEpoch 9: loss = 2.0475\nEpoch 10: loss = 2.0459\nEpoch 11: loss = 2.0453\nEpoch 12: loss = 2.0439\nEpoch 13: loss = 2.0436\nEpoch 14: loss = 2.0427\nEpoch 15: loss = 2.0423\nEpoch 16: loss = 2.0425\nEpoch 17: loss = 2.0422\nEpoch 18: loss = 2.0415\nEpoch 19: loss = 2.0420\nEpoch 20: loss = 2.0413\nEpoch 21: loss = 2.0404\nEpoch 22: loss = 2.0413\nEpoch 23: loss = 2.0395\nEpoch 24: loss = 2.0411\nEpoch 25: loss = 2.0395\nEpoch 26: loss = 2.0401\nEpoch 27: loss = 2.0396\nEpoch 28: loss = 2.0393\nEpoch 29: loss = 2.0385\nEpoch 30: loss = 2.0384\nEpoch 31: loss = 2.0386\nEpoch 32: loss = 2.0377\nEpoch 33: loss = 2.0375\nEpoch 34: loss = 2.0373\nEpoch 35: loss = 2.0367\nEpoch 36: loss = 2.0367\nEpoch 37: loss = 2.0361\nEpoch 38: loss = 2.0355\nEpoch 39: loss = 2.0357\nEpoch 40: loss = 2.0346\nEpoch 41: loss = 2.0352\nEpoch 42: loss = 2.0345\nEpoch 43: loss = 2.0350\nEpoch 44: loss = 2.0338\nEpoch 45: loss = 2.0337\nEpoch 46: loss = 2.0337\nEpoch 47: loss = 2.0323\nEpoch 48: loss = 2.0336\nEpoch 49: loss = 2.0323\nEpoch 50: loss = 2.0329\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"PoincareEmbedding(\n  (emb): Embedding(8000, 30)\n)"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom scipy import sparse\n\nEPS = 1e-5\n\ndef poincare_distance(x, y):\n    \"\"\"\n    Стандартное расстояние в шаре Пуанкаре\n    x, y: (..., d)\n    \"\"\"\n    x2 = (x * x).sum(dim=-1)\n    y2 = (y * y).sum(dim=-1)\n    diff2 = ((x - y) ** 2).sum(dim=-1)\n    denom = (1 - x2) * (1 - y2)\n    z = 1 + 2 * diff2 / denom.clamp_min(EPS)\n    return torch.acosh(z.clamp_min(1 + EPS))\n\n\ndef hyperbolic_cosine_distance(x, y):\n    \"\"\"\n    Гиперболический аналог косинусного сходства:\n    dist = 1 - <x, y>_L / (||x||_L * ||y||_L)\n    В простейшей форме используем обычный dot, нормируем по норме в шаре.\n    \"\"\"\n    x_norm = torch.norm(x, dim=-1, keepdim=True).clamp_min(EPS)\n    y_norm = torch.norm(y, dim=-1, keepdim=True).clamp_min(EPS)\n    cos_sim = (x @ y.transpose(-2, -1)) / (x_norm * y_norm.transpose(-2, -1))\n    return 1 - cos_sim\n\n\ndef euclidean_distance(x, y):\n    return torch.sqrt(((x - y) ** 2).sum(dim=-1))\n\n\n@torch.no_grad()\ndef pairwise_distance(emb, metric='poincare'):\n    \"\"\"\n    Возвращает матрицу попарных расстояний для всех эмбеддингов.\n    \"\"\"\n    x = emb.unsqueeze(1)  # (n,1,d)\n    y = emb.unsqueeze(0)  # (1,n,d)\n    \n    if metric == 'poincare':\n        return poincare_distance(x, y)\n    elif metric == 'hyperbolic_cosine':\n        return hyperbolic_cosine_distance(x, y)\n    elif metric == 'euclidean':\n        return euclidean_distance(x, y)\n    else:\n        raise ValueError(f\"Unknown metric: {metric}\")\n\n\n@torch.no_grad()\ndef knn_hyperbolic(model, k=10, metric='poincare'):\n    emb = model.emb.weight\n    dist = pairwise_distance(emb, metric=metric)\n    knn = torch.topk(dist, k=k+1, largest=False).indices[:, 1:]\n    return knn\n\n\ndef build_user_hyperbolic_knn(model, topk=100, device='cpu', metric='poincare'):\n    with torch.no_grad():\n        emb = model.emb.weight.to(device)\n        n = emb.shape[0]\n\n        rows, cols, data = [], [], []\n\n        for i in range(n):\n            xi = emb[i].unsqueeze(0)\n            if metric == 'poincare':\n                d = poincare_distance(xi, emb).cpu().numpy()\n            elif metric == 'hyperbolic_cosine':\n                d = hyperbolic_cosine_distance(xi, emb).cpu().numpy().flatten()\n            elif metric == 'euclidean':\n                d = euclidean_distance(xi, emb).cpu().numpy().flatten()\n            else:\n                raise ValueError(f\"Unknown metric: {metric}\")\n\n            d[i] = np.inf\n            idx = np.argpartition(d, topk)[:topk]\n            idx = idx[np.argsort(d[idx])]\n\n            rows.extend([i] * len(idx))\n            cols.extend(idx.tolist())\n            data.extend(np.exp(-d[idx]).astype(np.float32))\n\n    return sparse.csr_matrix(\n        (data, (rows, cols)),\n        shape=(n, n)\n    )","metadata":{"execution":{"iopub.status.busy":"2025-12-21T22:07:33.659210Z","iopub.execute_input":"2025-12-21T22:07:33.659683Z","iopub.status.idle":"2025-12-21T22:07:33.672887Z","shell.execute_reply.started":"2025-12-21T22:07:33.659657Z","shell.execute_reply":"2025-12-21T22:07:33.672290Z"},"trusted":true},"outputs":[],"execution_count":11},{"cell_type":"code","source":"S_knn = build_user_hyperbolic_knn(user_model, topk=200, metric='poincare')\nS_knn_cos = build_user_hyperbolic_knn(user_model, topk=200, metric='hyperbolic_cosine')\nS_knn_euc = build_user_hyperbolic_knn(user_model, topk=200, metric='euclidean')","metadata":{"execution":{"iopub.status.busy":"2025-12-21T22:08:53.895084Z","iopub.execute_input":"2025-12-21T22:08:53.895733Z","iopub.status.idle":"2025-12-21T22:09:07.236052Z","shell.execute_reply.started":"2025-12-21T22:08:53.895701Z","shell.execute_reply":"2025-12-21T22:09:07.235238Z"},"trusted":true},"outputs":[],"execution_count":16},{"cell_type":"code","source":"userknn_hyper_rec = userknn_recommender_factory(X_raw, S_knn)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-21T22:09:07.237711Z","iopub.execute_input":"2025-12-21T22:09:07.238041Z","iopub.status.idle":"2025-12-21T22:09:07.242972Z","shell.execute_reply.started":"2025-12-21T22:09:07.238006Z","shell.execute_reply":"2025-12-21T22:09:07.242229Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"def recall_at_k(pred_items, true_items, k):\n    \"\"\"\n    Recall@K = доля товаров из истинной корзины, которые попали в top-K рекомендаций.\n    true_items: список товаров в истинной корзине (val/test)\n    pred_items: ранжированный список рекомендаций\n    \"\"\"\n    pred_k = pred_items[:k]\n    true_set = set(true_items)\n    if len(true_set) == 0:\n        return 0.0\n    return len(set(pred_k) & true_set) / len(true_set)\n\ndef ndcg_at_k(pred_items, true_items, k):\n    \"\"\"\n    NDCG@K учитывает порядок: попадания в верхние позиции оцениваются выше.\n    Здесь релевантность бинарная: товар релевантен, если он есть в true_items.\n    \"\"\"\n    true_set = set(true_items)\n    pred_k = pred_items[:k]\n\n    # DCG\n    dcg = 0.0\n    for i, it in enumerate(pred_k):\n        if it in true_set:\n            dcg += 1.0 / np.log2(i + 2)  # i=0 -> log2(2)=1\n\n    # IDCG: максимум возможного DCG при идеальном ранжировании\n    ideal_hits = min(k, len(true_set))\n    idcg = sum(1.0 / np.log2(i + 2) for i in range(ideal_hits))\n\n    return dcg / idcg if idcg > 0 else 0.0\n\ndef evaluate_model(recommender_fn, users, true_baskets, topk_list=(5,10,20)):\n    \"\"\"\n    Оцениваем модель на пользователях:\n    - recommender_fn(u) должен возвращать ранжированный список item_id (индексы товаров)\n    - true_baskets[u] — истинная корзина (список item_id)\n    Возвращаем средние Recall@K и NDCG@K по пользователям для каждого K.\n    \"\"\"\n    rows = []\n    for u in users:\n        u = int(u)\n        pred = recommender_fn(u)\n        true = true_baskets[u]\n        for k in topk_list:\n            rows.append({\n                \"u\": u,\n                \"k\": int(k),\n                \"recall\": recall_at_k(pred, true, k),\n                \"ndcg\": ndcg_at_k(pred, true, k),\n            })\n\n    return (pd.DataFrame(rows)\n            .groupby(\"k\")[[\"recall\",\"ndcg\"]].mean()\n            .reset_index())\n\ndef tag_result(df_res, model_name, split_name):\n    \"\"\"Добавляем метаданные (название модели и сплит) к таблице метрик.\"\"\"\n    out = df_res.copy()\n    out[\"model\"] = model_name\n    out[\"split\"] = split_name\n    return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-21T22:09:07.244002Z","iopub.execute_input":"2025-12-21T22:09:07.244300Z","iopub.status.idle":"2025-12-21T22:09:07.255030Z","shell.execute_reply.started":"2025-12-21T22:09:07.244268Z","shell.execute_reply":"2025-12-21T22:09:07.254523Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"\nusers_val = list(val_basket.keys())\nres_userknn_hyper_val = evaluate_model(\n    lambda u: userknn_hyper_rec(u, TOPN_RECOMMEND),\n    users_val,\n    val_basket,\n    TOPK_LIST\n)\n\nval_table_user = pd.concat([\n    tag_result(res_userknn_hyper_val, f\"UserKNN_Hyper(topk={USERKNN_DEFAULT_K})\", \"val\"),\n], ignore_index=True)\n\nval_table_user\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-21T22:15:47.115307Z","iopub.execute_input":"2025-12-21T22:15:47.115990Z","iopub.status.idle":"2025-12-21T22:15:50.686660Z","shell.execute_reply.started":"2025-12-21T22:15:47.115961Z","shell.execute_reply":"2025-12-21T22:15:50.686023Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"    k    recall      ndcg                    model split\n0   5  0.034583  0.050009  UserKNN_Hyper(topk=200)   val\n1  10  0.050274  0.050201  UserKNN_Hyper(topk=200)   val\n2  20  0.068994  0.054593  UserKNN_Hyper(topk=200)   val","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>k</th>\n      <th>recall</th>\n      <th>ndcg</th>\n      <th>model</th>\n      <th>split</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5</td>\n      <td>0.034583</td>\n      <td>0.050009</td>\n      <td>UserKNN_Hyper(topk=200)</td>\n      <td>val</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10</td>\n      <td>0.050274</td>\n      <td>0.050201</td>\n      <td>UserKNN_Hyper(topk=200)</td>\n      <td>val</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20</td>\n      <td>0.068994</td>\n      <td>0.054593</td>\n      <td>UserKNN_Hyper(topk=200)</td>\n      <td>val</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"userknn_hyper_rec = userknn_recommender_factory(X_raw, S_knn)\nusers_test = list(test_basket.keys())\nres_userknn_hyper_test = evaluate_model(\n    lambda u: userknn_hyper_rec(u, TOPN_RECOMMEND),\n    users_test,\n    test_basket,\n    TOPK_LIST\n)\n\ntest_table_user = pd.concat([\n    tag_result(res_userknn_hyper_test, f\"UserKNN_Hyper(topk={USERKNN_DEFAULT_K})\", \"test\"),\n], ignore_index=True)\n\ntest_table_user\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-21T22:17:04.936759Z","iopub.execute_input":"2025-12-21T22:17:04.937309Z","iopub.status.idle":"2025-12-21T22:17:09.997991Z","shell.execute_reply.started":"2025-12-21T22:17:04.937279Z","shell.execute_reply":"2025-12-21T22:17:09.997415Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"    k    recall      ndcg                    model split\n0   5  0.060735  0.078083  UserKNN_Hyper(topk=200)  test\n1  10  0.075807  0.076244  UserKNN_Hyper(topk=200)  test\n2  20  0.095728  0.081010  UserKNN_Hyper(topk=200)  test","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>k</th>\n      <th>recall</th>\n      <th>ndcg</th>\n      <th>model</th>\n      <th>split</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5</td>\n      <td>0.060735</td>\n      <td>0.078083</td>\n      <td>UserKNN_Hyper(topk=200)</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10</td>\n      <td>0.075807</td>\n      <td>0.076244</td>\n      <td>UserKNN_Hyper(topk=200)</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20</td>\n      <td>0.095728</td>\n      <td>0.081010</td>\n      <td>UserKNN_Hyper(topk=200)</td>\n      <td>test</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}